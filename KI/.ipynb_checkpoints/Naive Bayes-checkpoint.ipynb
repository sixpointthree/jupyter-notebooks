{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "23aec640",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "722c2557",
   "metadata": {},
   "outputs": [],
   "source": [
    "C = np.random.normal(loc=0.5, scale=0.2, size=12)*10\n",
    "for i in range(0, len(C)): C[i] = int(C[i])\n",
    "X = np.array([\n",
    "    [0, 0, C[0],  1],\n",
    "    [0, 0, C[1],  0],\n",
    "    [0, 1, C[2],  1],\n",
    "    [0, 1, C[3],  0],\n",
    "    [0, 1, C[4],  0],\n",
    "    [1, 0, C[5],  1],\n",
    "    [1, 0, C[6],  1],\n",
    "    [1, 0, C[7],  0],\n",
    "    [1, 1, C[8],  1],\n",
    "    [1, 1, C[9],  0],\n",
    "    [1, 1, C[10], 1],\n",
    "    [1, 1, C[11], 1],\n",
    "])\n",
    "y = [\n",
    "    1,\n",
    "    1,\n",
    "    0,\n",
    "    1,\n",
    "    0,\n",
    "    1,\n",
    "    1,\n",
    "    1,\n",
    "    0,\n",
    "    0,\n",
    "    1,\n",
    "    0,\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "5f6e09a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 6. 1.]\n",
      " [0. 0. 9. 0.]\n",
      " [0. 1. 6. 1.]\n",
      " [0. 1. 5. 0.]\n",
      " [0. 1. 3. 0.]\n",
      " [1. 0. 4. 1.]\n",
      " [1. 0. 3. 1.]\n",
      " [1. 0. 5. 0.]\n",
      " [1. 1. 4. 1.]\n",
      " [1. 1. 1. 0.]\n",
      " [1. 1. 3. 1.]\n",
      " [1. 1. 5. 1.]]\n",
      "[1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0]\n"
     ]
    }
   ],
   "source": [
    "print(X)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "6ed0229e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CategoricalNB()"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import CategoricalNB\n",
    "clf = CategoricalNB()\n",
    "clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "d4910f6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'alpha': 1.0, 'class_prior': None, 'fit_prior': True, 'min_categories': None}"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "12f79432",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 0 0 0 1 1 1 0 0 0 0]\n",
      "[[-1.91870808 -0.15875718]\n",
      " [-2.59519931 -0.0775627 ]\n",
      " [-0.39497427 -1.11993002]\n",
      " [-0.57377428 -0.8287264 ]\n",
      " [-0.57377428 -0.8287264 ]\n",
      " [-1.86390841 -0.16849603]\n",
      " [-2.21630132 -0.11542383]\n",
      " [-2.2740033  -0.10858729]\n",
      " [-0.37436953 -1.1638638 ]\n",
      " [-0.21686227 -1.63496519]\n",
      " [-0.51945522 -0.90348438]\n",
      " [-0.51945522 -0.90348438]]\n",
      "[[0.14679649 0.85320351]\n",
      " [0.074631   0.925369  ]\n",
      " [0.67369737 0.32630263]\n",
      " [0.56339501 0.43660499]\n",
      " [0.56339501 0.43660499]\n",
      " [0.15506538 0.84493462]\n",
      " [0.10901156 0.89098844]\n",
      " [0.10289942 0.89710058]\n",
      " [0.68772273 0.31227727]\n",
      " [0.80504084 0.19495916]\n",
      " [0.59484452 0.40515548]\n",
      " [0.59484452 0.40515548]]\n",
      "0.8333333333333334\n"
     ]
    }
   ],
   "source": [
    "# single feature: reshape(-1, 1)\n",
    "# single value: reshape(1, -1)\n",
    "print(clf.predict(X))\n",
    "print(clf.predict_log_proba(X))\n",
    "print(clf.predict_proba(X))\n",
    "print(clf.score(X, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "3dc89145",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Class 0       0.71      1.00      0.83         5\n",
      "     Class 1       1.00      0.71      0.83         7\n",
      "\n",
      "    accuracy                           0.83        12\n",
      "   macro avg       0.86      0.86      0.83        12\n",
      "weighted avg       0.88      0.83      0.83        12\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score, classification_report\n",
    "print(classification_report(y, clf.predict(X), target_names=['Class 0', 'Class 1']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "0086f92e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\n"
     ]
    }
   ],
   "source": [
    "print(clf.predict([[1, 1, 5, 0]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "6779b11f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### A\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00         5\n",
      "         1.0       0.58      1.00      0.74         7\n",
      "\n",
      "    accuracy                           0.58        12\n",
      "   macro avg       0.29      0.50      0.37        12\n",
      "weighted avg       0.34      0.58      0.43        12\n",
      "\n",
      "### B\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.71      1.00      0.83         5\n",
      "         1.0       1.00      0.71      0.83         7\n",
      "\n",
      "    accuracy                           0.83        12\n",
      "   macro avg       0.86      0.86      0.83        12\n",
      "weighted avg       0.88      0.83      0.83        12\n",
      "\n",
      "### C\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.00      0.00      0.00         1\n",
      "         3.0       0.25      1.00      0.40         3\n",
      "         4.0       0.00      0.00      0.00         2\n",
      "         5.0       0.00      0.00      0.00         3\n",
      "         6.0       0.00      0.00      0.00         2\n",
      "         9.0       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.25        12\n",
      "   macro avg       0.04      0.17      0.07        12\n",
      "weighted avg       0.06      0.25      0.10        12\n",
      "\n",
      "### D\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00         5\n",
      "         1.0       0.58      1.00      0.74         7\n",
      "\n",
      "    accuracy                           0.58        12\n",
      "   macro avg       0.29      0.50      0.37        12\n",
      "weighted avg       0.34      0.58      0.43        12\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Steffen\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Steffen\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Steffen\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Steffen\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Steffen\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Steffen\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Steffen\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Steffen\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Steffen\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Einzelwahrscheinlichkeiten pro Feature:\n",
    "# p(a=1) = 4/7\n",
    "# p(b=1) = 2/7\n",
    "# p(c=1) ???\n",
    "# p(d=1) = 4/7\n",
    "\n",
    "\n",
    "# Mit Modelle\n",
    "A = np.array(X[:,0])\n",
    "B = np.array(X[:,1])\n",
    "C = np.array(X[:,2])\n",
    "D = np.array(X[:,3])\n",
    "class_y = np.array(y).reshape(-1, 1)\n",
    "nb = CategoricalNB()\n",
    "print(\"### A\")\n",
    "nb.fit(class_y, A)\n",
    "print(classification_report(A, nb.predict(class_y)))\n",
    "print(\"### B\")\n",
    "nb.fit(class_y, B)\n",
    "print(classification_report(B, nb.predict(class_y)))\n",
    "print(\"### C\")\n",
    "nb.fit(class_y, C)\n",
    "print(classification_report(C, nb.predict(class_y)))\n",
    "print(\"### D\")\n",
    "nb.fit(class_y, D)\n",
    "print(classification_report(D, nb.predict(class_y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0283353a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
