{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aufgaben Linear Networks\n",
    "========================\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the common imports:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression Network\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following exercise you should create a linear regression\n",
    "model from scratch and test it on some synthetically created data:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100, 2]) torch.Size([100, 1])\n"
     ]
    }
   ],
   "source": [
    "def synthetic_data(w, b, num_examples):  #@save\n",
    "    \"\"\"Generate y = Xw + b + noise.\"\"\"\n",
    "    X = torch.normal(0, 1, (num_examples, len(w)))\n",
    "    y = torch.matmul(X, w) + b\n",
    "    # Rauschen dazu addieren, Form von y\n",
    "    y += torch.normal(0, 0.01, y.shape)\n",
    "    return X, y.reshape((-1, 1))\n",
    "\n",
    "true_w = torch.tensor([2, -3.4])\n",
    "true_b = 4.2\n",
    "\n",
    "n_samples=100\n",
    "X, y = synthetic_data(true_w, true_b, n_samples)\n",
    "K = 2\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our goal is to fit a simple regression model with Batch Gradient Descent.\n",
    "We start with randomly chosen values for the weights and zero bias.\n",
    "First, implement the function below.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100, 2])\n",
      "torch.Size([2, 1])\n",
      "torch.Size([1])\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(0)\n",
    "w = torch.normal(0, 0.01, size=(K, 1))\n",
    "b = torch.zeros(1)\n",
    "print(X.shape)\n",
    "print(w.shape)\n",
    "print(b.shape)\n",
    "\n",
    "def linreg(X, w, b):\n",
    "    \"\"\"The linear regression model.\"\"\"\n",
    "    return torch.matmul(X, w) + b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to define the loss functions to be used:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "def squared_loss(y_hat, y):\n",
    "    assert y_hat.shape == y.shape\n",
    "    return 0.5*((y_hat -y)**2).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to implement the training loop for Gradient Descent.\n",
    "You should not use `autograd` for computing the gradient, instead\n",
    "build on the closed formula presented in the lecture.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True weights: tensor([ 2.0000, -3.4000])\n",
      "Epoch(0):\n",
      "  - Gradients: tensor([-2.8184,  3.3779])\n",
      "  - New Weights: tensor([[ 0.2973],\n",
      "        [-0.3407]])\n",
      "  - New Bias: tensor([0.3503])\n",
      "Epoch(10):\n",
      "  - Gradients: tensor([-0.6558,  1.1300])\n",
      "  - New Weights: tensor([[ 1.6873],\n",
      "        [-2.2630]])\n",
      "  - New Bias: tensor([2.6115])\n",
      "Epoch(20):\n",
      "  - Gradients: tensor([-0.1247,  0.4224])\n",
      "  - New Weights: tensor([[ 1.9899],\n",
      "        [-2.9416]])\n",
      "  - New Bias: tensor([3.5520])\n",
      "Epoch(30):\n",
      "  - Gradients: tensor([-0.0070,  0.1709])\n",
      "  - New Weights: tensor([[ 2.0348],\n",
      "        [-3.2058]])\n",
      "  - New Bias: tensor([3.9353])\n",
      "Epoch(40):\n",
      "  - Gradients: tensor([0.0113, 0.0725])\n",
      "  - New Weights: tensor([[ 2.0283],\n",
      "        [-3.3154]])\n",
      "  - New Bias: tensor([4.0907])\n",
      "Epoch(50):\n",
      "  - Gradients: tensor([0.0095, 0.0315])\n",
      "  - New Weights: tensor([[ 2.0175],\n",
      "        [-3.3625]])\n",
      "  - New Bias: tensor([4.1541])\n",
      "Epoch(60):\n",
      "  - Gradients: tensor([0.0056, 0.0139])\n",
      "  - New Weights: tensor([[ 2.0102],\n",
      "        [-3.3831]])\n",
      "  - New Bias: tensor([4.1801])\n",
      "Epoch(70):\n",
      "  - Gradients: tensor([0.0029, 0.0061])\n",
      "  - New Weights: tensor([[ 2.0062],\n",
      "        [-3.3922]])\n",
      "  - New Bias: tensor([4.1908])\n",
      "Epoch(80):\n",
      "  - Gradients: tensor([0.0014, 0.0027])\n",
      "  - New Weights: tensor([[ 2.0042],\n",
      "        [-3.3962]])\n",
      "  - New Bias: tensor([4.1953])\n",
      "Epoch(90):\n",
      "  - Gradients: tensor([0.0007, 0.0012])\n",
      "  - New Weights: tensor([[ 2.0032],\n",
      "        [-3.3980]])\n",
      "  - New Bias: tensor([4.1972])\n",
      "Final weights: tensor([[ 2.0027],\n",
      "        [-3.3987]])\n",
      "Final bias: tensor([4.1980])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2b3fe1b3250>]"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "step = 0.1\n",
    "n_epoch = 100\n",
    "\n",
    "loss_arr = np.zeros(n_epoch) # to record current loss\n",
    "print(f\"True weights: {true_w}\")\n",
    "\n",
    "for epoch in range(n_epoch):\n",
    "    # 1.  Compute the prediction y_hat\n",
    "    y_hat = linreg(X, w, b)\n",
    "    # remember the loss for plotting it later\n",
    "    loss_arr[epoch] = squared_loss(y_hat, y)\n",
    "    # 2. Use y_hat and y to compute the gradients\n",
    "    gradient_vals = torch.zeros(len(X), len(w))\n",
    "    bias_grad_vals = torch.zeros(len(X), 1)\n",
    "    #bias ergänzen!!!!!!!!!!!!\n",
    "    for i in range(0, len(X)):\n",
    "        gradient_vals[i] = (y_hat[i] - y[i]) * X[i]\n",
    "        bias_grad_vals[i] = (y_hat[i] - y[i])\n",
    "    gradients = torch.mean(gradient_vals, 0)\n",
    "    bias_gradients = torch.mean(bias_grad_vals, 0)\n",
    "    # 3. Update the parameters\n",
    "    w = w - step * gradients.reshape(-1, 1)\n",
    "    b = b - step * bias_gradients\n",
    "    if epoch % 10 == 0:\n",
    "        print(f\"Epoch({epoch}):\")\n",
    "        print(f\"  - Gradients: {gradients}\")\n",
    "        print(f\"  - New Weights: {w}\")\n",
    "        print(f\"  - New Bias: {b}\")\n",
    "print(f\"Final weights: {w}\")\n",
    "print(f\"Final bias: {b}\")\n",
    "plt.plot(loss_arr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear networks with autograd\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal now is to use `autograd` the compute the gradient.\n",
    "You can use the same skeleton as before\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch(0):\n",
      "  - New Weights: tensor([[ 0.2973],\n",
      "        [-0.3407]], requires_grad=True)\n",
      "  - New Bias: tensor([0.3503], requires_grad=True)\n",
      "Epoch(10):\n",
      "  - New Weights: tensor([[ 1.6873],\n",
      "        [-2.2630]], requires_grad=True)\n",
      "  - New Bias: tensor([2.6115], requires_grad=True)\n",
      "Epoch(20):\n",
      "  - New Weights: tensor([[ 1.9899],\n",
      "        [-2.9416]], requires_grad=True)\n",
      "  - New Bias: tensor([3.5520], requires_grad=True)\n",
      "Epoch(30):\n",
      "  - New Weights: tensor([[ 2.0348],\n",
      "        [-3.2058]], requires_grad=True)\n",
      "  - New Bias: tensor([3.9353], requires_grad=True)\n",
      "Epoch(40):\n",
      "  - New Weights: tensor([[ 2.0283],\n",
      "        [-3.3154]], requires_grad=True)\n",
      "  - New Bias: tensor([4.0907], requires_grad=True)\n",
      "Epoch(50):\n",
      "  - New Weights: tensor([[ 2.0175],\n",
      "        [-3.3625]], requires_grad=True)\n",
      "  - New Bias: tensor([4.1541], requires_grad=True)\n",
      "Epoch(60):\n",
      "  - New Weights: tensor([[ 2.0102],\n",
      "        [-3.3831]], requires_grad=True)\n",
      "  - New Bias: tensor([4.1801], requires_grad=True)\n",
      "Epoch(70):\n",
      "  - New Weights: tensor([[ 2.0062],\n",
      "        [-3.3922]], requires_grad=True)\n",
      "  - New Bias: tensor([4.1908], requires_grad=True)\n",
      "Epoch(80):\n",
      "  - New Weights: tensor([[ 2.0042],\n",
      "        [-3.3962]], requires_grad=True)\n",
      "  - New Bias: tensor([4.1953], requires_grad=True)\n",
      "Epoch(90):\n",
      "  - New Weights: tensor([[ 2.0032],\n",
      "        [-3.3980]], requires_grad=True)\n",
      "  - New Bias: tensor([4.1972], requires_grad=True)\n",
      "Final weights: tensor([[ 2.0027],\n",
      "        [-3.3987]], requires_grad=True)\n",
      "Final bias: tensor([4.1980], requires_grad=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2b3fe37c370>]"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "torch.manual_seed(0)\n",
    "w = torch.normal(0, 0.01, size=(K,1), requires_grad=True)\n",
    "b = torch.zeros(1, requires_grad=True)\n",
    "\n",
    "step = 0.1\n",
    "n_epoch = 100\n",
    "\n",
    "loss_arr = torch.zeros(n_epoch) # to record current loss\n",
    "\n",
    "for epoch in range(n_epoch):\n",
    "    # 1.  Compute the prediction y_hat\n",
    "    y_hat = linreg(X, w, b)\n",
    "    # remember the loss for plotting it later\n",
    "    loss = squared_loss(y_hat, y)\n",
    "    loss_arr[epoch] = loss.detach()\n",
    "    # 2. Use the computed loss to compute the gradients\n",
    "    loss.backward()\n",
    "    with torch.no_grad():\n",
    "        w -= step*w.grad/n_samples\n",
    "        b -= step*b.grad/n_samples\n",
    "        w.grad.zero_()\n",
    "        b.grad.zero_()\n",
    "    \n",
    "    if epoch % 10 == 0:\n",
    "        print(f\"Epoch({epoch}):\")\n",
    "        print(f\"  - New Weights: {w}\")\n",
    "        print(f\"  - New Bias: {b}\")\n",
    "print(f\"Final weights: {w}\")\n",
    "print(f\"Final bias: {b}\")\n",
    "\n",
    "plt.plot(loss_arr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear classification\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We  want to implement a linear network for classification.\n",
    "We use the famous IRIS data set as an example.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "X, y = load_iris(return_X_y=True)\n",
    "X = torch.tensor(X, dtype=torch.float32)\n",
    "y = torch.tensor(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This time the network is implemented as a class,\n",
    "the only thing missing is the implementation of the softmax function,\n",
    "for example\n",
    "$$\n",
    "softmax(y)_1 = \\frac{e^{y_1}}{ \\sum_{i=1}^p  e^{y_i} }.\n",
    "$$\n",
    "You have to implement it below.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 1])\n",
      "tensor([-0.0141, -0.0156, -0.0042])\n",
      "tensor([0, 0, 0])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steffen.lang\\AppData\\Local\\Temp\\ipykernel_18656\\1668991339.py:14: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(y_exp, dtype=int)\n"
     ]
    }
   ],
   "source": [
    "def softmax(y):\n",
    "    y_exp_one_hot = torch.exp(y)\n",
    "    y_exp = torch.zeros(len(y))\n",
    "    partition = y_exp_one_hot.sum(axis=1, keepdims=True)\n",
    "    y_exp_one_hot = y_exp_one_hot / partition\n",
    "    print(y_exp_one_hot.shape)\n",
    "    for i, row in enumerate(y):\n",
    "        max_val = row[0]\n",
    "        for j, col in enumerate(row):\n",
    "            if col > max_val:\n",
    "                max_val = j\n",
    "        y_exp[i] = max_val\n",
    "    print(y_exp)\n",
    "    return torch.tensor(y_exp, dtype=int)\n",
    "\n",
    "print(softmax(torch.normal(0, 0.01, size=(3, 1), dtype=torch.float64)))\n",
    "\n",
    "class SoftmaxNetwork:\n",
    "\n",
    "    def __init__(self, num_input, num_output, dtype=torch.float64):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            num_input: dimension of input space\n",
    "            num_output: number if output classes\n",
    "        \"\"\"\n",
    "        self.w = torch.randn((num_input,num_output),\n",
    "                             dtype=dtype).requires_grad_(True)\n",
    "        self.b = torch.randn(num_output, dtype=dtype).requires_grad_(True)\n",
    "\n",
    "    def forward(self, X):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            X: tensor of shape (n, d)\n",
    "        \"\"\"\n",
    "        y = (X @ self.w + self.b)\n",
    "        return softmax(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we have to implement the cross entropy loss, it is already finished:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_entropy(y_hat, y):\n",
    "    return (-torch.log(y_hat[range(len(y_hat)), y])).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that this implementation does not require a one-hot-encoding for $y$\n",
    "(but there is one side effect: $y$ has to be of type `torch.int64`!).\n",
    "\n",
    "The final step is to implement a function that runs the training for us:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_training(net, X, y, f_loss, n_epochs, lr=0.1):\n",
    "    train_loss = np.zeros(n_epochs)\n",
    "    \n",
    "    for epoch in range(0, n_epochs):\n",
    "        y_hat = net.forward(X)\n",
    "        print(type(y_hat), y_hat.shape)\n",
    "        print(type(y), y.shape)\n",
    "        loss = f_loss(y_hat, y)\n",
    "        loss.backward()\n",
    "        with torch.no_grad():\n",
    "            net.w -= lr*net.w.grad\n",
    "            net.b -= lr*net.b.grad\n",
    "            net.w.grad.zero_()\n",
    "            net.b.grad.zero_()\n",
    "        train_loss[epoch] = loss\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now train the model, don't forget to cast X and y to Pytorch tensors.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([150, 3])\n",
      "tensor([2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2.,\n",
      "        2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2.,\n",
      "        2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2.,\n",
      "        2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2.,\n",
      "        2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2.,\n",
      "        2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2.,\n",
      "        2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2.,\n",
      "        2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2.,\n",
      "        2., 2., 2., 2., 2., 2.])\n",
      "<class 'torch.Tensor'> torch.Size([150])\n",
      "<class 'torch.Tensor'> torch.Size([150])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steffen.lang\\AppData\\Local\\Temp\\ipykernel_18656\\1668991339.py:14: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(y_exp, dtype=int)\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "too many indices for tensor of dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [217]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m net \u001b[38;5;241m=\u001b[39m SoftmaxNetwork(\u001b[38;5;241m4\u001b[39m,\u001b[38;5;241m3\u001b[39m, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat32)\n\u001b[1;32m----> 2\u001b[0m train_loss \u001b[38;5;241m=\u001b[39m \u001b[43mrun_training\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnet\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[43mcross_entropy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.2\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(train_loss)\n\u001b[0;32m      5\u001b[0m plt\u001b[38;5;241m.\u001b[39mxlabel(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mepochs\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "Input \u001b[1;32mIn [216]\u001b[0m, in \u001b[0;36mrun_training\u001b[1;34m(net, X, y, f_loss, n_epochs, lr)\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mtype\u001b[39m(y_hat), y_hat\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mtype\u001b[39m(y), y\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m----> 8\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[43mf_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_hat\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      9\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n",
      "Input \u001b[1;32mIn [215]\u001b[0m, in \u001b[0;36mcross_entropy\u001b[1;34m(y_hat, y)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcross_entropy\u001b[39m(y_hat, y):\n\u001b[1;32m----> 2\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;241m-\u001b[39mtorch\u001b[38;5;241m.\u001b[39mlog(\u001b[43my_hat\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mrange\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43my_hat\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m]\u001b[49m))\u001b[38;5;241m.\u001b[39mmean()\n",
      "\u001b[1;31mIndexError\u001b[0m: too many indices for tensor of dimension 1"
     ]
    }
   ],
   "source": [
    "net = SoftmaxNetwork(4,3, dtype=torch.float32)\n",
    "train_loss = run_training(net, X, y,  cross_entropy, n_epochs=100, lr=0.2)\n",
    "\n",
    "plt.plot(train_loss)\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('loss')\n",
    "plt.title('Learning curve');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.  Run the training several times, and observe the different learning curves.\n",
    "2.  Try the same with a lower learning rate, say $lr=0.05$. Do you see any differences?\n",
    "\n",
    "Finally check the accuracy of the model, that is the fraction of correctly predicted examples.\n",
    "Of course this is on training only. If you like you can try to split the\n",
    "data into train and test and evaluate your network on the test data set.\n",
    "A useful function for this is `train_test_split` found in `sklearn.model_selection`.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "org": null,
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
